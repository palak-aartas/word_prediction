{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sw/mplph8ks42g1krcbdjk6xg8c0000gn/T/ipykernel_76525/448611605.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prescription data extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import pandas as pd\n",
    "\n",
    "db_config = {\n",
    "    \"host\": \"database-1.cvg820c68twg.ap-south-1.rds.amazonaws.com\",\n",
    "    \"user\": \"admin\",\n",
    "    \"password\": \"Password!23\",\n",
    "    \"database\": \"galen_chat\"\n",
    "}\n",
    "\n",
    "conn = pymysql.connect(**db_config)\n",
    "query = \"SELECT epad_text,speciality FROM clinisquare_db WHERE epad_text IS NOT NULL\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "df.to_csv(\"prescription_data/prescriptions_raw.csv\", index=False)\n",
    "\n",
    "conn.close()\n",
    "print(\"Prescription data extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           epad_text         speciality\n",
      "0  ID: #P22S404 | Neeta Lal (female , 37) Date: M...        Orthopedics\n",
      "1  OPD Note ID: #P28S01 | Name: Rohit Jha | Age: ...    Family Medicine\n",
      "2  Untitled ID: #P07S01 | Name: vikas natekar | A...         Pediatrics\n",
      "3  OPD Note ID: #P04S01 | Name: Kabir Sharma | Ag...  Internal Medicine\n",
      "4  Clinical Notes ID: #P24S127 | Aditya Singh (ma...        Dermatology\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"prescription_data/prescriptions_raw.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epad_text</th>\n",
       "      <th>speciality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID: #P22S404 | Neeta Lal (female , 37) Date: M...</td>\n",
       "      <td>Orthopedics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPD Note ID: #P28S01 | Name: Rohit Jha | Age: ...</td>\n",
       "      <td>Family Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Untitled ID: #P07S01 | Name: vikas natekar | A...</td>\n",
       "      <td>Pediatrics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OPD Note ID: #P04S01 | Name: Kabir Sharma | Ag...</td>\n",
       "      <td>Internal Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical Notes ID: #P24S127 | Aditya Singh (ma...</td>\n",
       "      <td>Dermatology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>ID: #P22S406 | Mina Sharma (female , 70) Date:...</td>\n",
       "      <td>Orthopedics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3263</th>\n",
       "      <td>ID: #P22S447 | Shalu Khandelwal (female , 39) ...</td>\n",
       "      <td>Orthopedics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>ID: #P03S07 | Prabhmeet P (female , 43) Date: ...</td>\n",
       "      <td>Physiotherapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3270</th>\n",
       "      <td>ID: #P198S24 | Chirag Shah (Male ) Date: Apr 0...</td>\n",
       "      <td>Sports Medicine and Arthroplasty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>ID: #P198S19 | Vinita Singhania (Female ) Date...</td>\n",
       "      <td>Sports Medicine and Arthroplasty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1342 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              epad_text  \\\n",
       "0     ID: #P22S404 | Neeta Lal (female , 37) Date: M...   \n",
       "1     OPD Note ID: #P28S01 | Name: Rohit Jha | Age: ...   \n",
       "2     Untitled ID: #P07S01 | Name: vikas natekar | A...   \n",
       "3     OPD Note ID: #P04S01 | Name: Kabir Sharma | Ag...   \n",
       "4     Clinical Notes ID: #P24S127 | Aditya Singh (ma...   \n",
       "...                                                 ...   \n",
       "3260  ID: #P22S406 | Mina Sharma (female , 70) Date:...   \n",
       "3263  ID: #P22S447 | Shalu Khandelwal (female , 39) ...   \n",
       "3264  ID: #P03S07 | Prabhmeet P (female , 43) Date: ...   \n",
       "3270  ID: #P198S24 | Chirag Shah (Male ) Date: Apr 0...   \n",
       "3274  ID: #P198S19 | Vinita Singhania (Female ) Date...   \n",
       "\n",
       "                            speciality  \n",
       "0                          Orthopedics  \n",
       "1                      Family Medicine  \n",
       "2                           Pediatrics  \n",
       "3                    Internal Medicine  \n",
       "4                          Dermatology  \n",
       "...                                ...  \n",
       "3260                       Orthopedics  \n",
       "3263                       Orthopedics  \n",
       "3264                     Physiotherapy  \n",
       "3270  Sports Medicine and Arthroplasty  \n",
       "3274  Sports Medicine and Arthroplasty  \n",
       "\n",
       "[1342 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[~df['epad_text'].astype(str).str.startswith(\"Patient History Form ID:\")]\n",
    "df = df[~df['epad_text'].astype(str).str.startswith(\"Informed Consent Form ID:\")]\n",
    "df = df[~df['epad_text'].astype(str).str.startswith(\"Medical Certificate\")]\n",
    "df = df[~df['epad_text'].astype(str).str.startswith(\"Certificate\")]\n",
    "# df = df[~df['epad_text'].astype(str).str.startswith(\"OPD Note  | Location: \")]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return text  \n",
    "    \n",
    "    text = re.sub(r\"ID: #\\S+ \\| .*? Date: .*?\\d{2}:\\d{2} (AM|PM)\", \"\", text)\n",
    "    text = re.sub(r\"OPD Note ID: #\\S+ \\| Name: .*? \\| Age: \\d+ \\| Gender: (male|female) \\| .*?\", \"\", text)\n",
    "    text = re.sub(r\"^(Clinical Notes|Prescription|Follow-up:|Vitals)\\s*\", \"\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"^(?:\\d{1,2}(st|nd|rd|th)?\\s+[A-Za-z]+\\s+\\d{2,4})\", \"\", text)\n",
    "    text = re.sub(r\"[●*]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.strip()\n",
    "\n",
    "df['epad_text'] = df['epad_text'].astype(str).apply(clean_text)\n",
    "df = df.dropna(subset=['epad_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"prescription_data/prescription_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "date_pattern = r\"\\b(?:\\d{1,2}[-/]\\d{1,2}[-/]\\d{2,4}|\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{1,2},? \\d{2,4})\\b\"\n",
    "id_pattern = r\"ID: #[A-Za-z0-9]+\"\n",
    "meta_patterns = [r\"Visit Date: .*?\\|\", r\"Location: .*?\\|\", r\"Name: .*?\\|\", r\"Age: \\d+ \\|\", r\"Gender: .*?\\|\"]\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  #lowercase\n",
    "    text = re.sub(date_pattern, \"\", text)  #dates\n",
    "    text = re.sub(id_pattern, \"\", text)  #IDs\n",
    "    for pattern in meta_patterns:\n",
    "        text = re.sub(pattern, \"\", text)  #metadata\n",
    "    text = re.sub(r\"\\d+\", \"\", text)  #standalone numbers\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  #special characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  #extra spaces\n",
    "    return text\n",
    "\n",
    "df[\"epad_text_clean\"] = df[\"epad_text\"].astype(str).apply(clean_text)\n",
    "\n",
    "df.to_csv(\"data/prescription_data/prescriptions_clean.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaning complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1000)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization & phrase extraction complete!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "df[\"tokenized\"] = df[\"epad_text_clean\"].apply(nltk.word_tokenize)\n",
    "\n",
    "unigrams = []\n",
    "bigrams = []\n",
    "trigrams = []\n",
    "\n",
    "for tokens in df[\"tokenized\"]:\n",
    "    unigrams.extend(tokens)\n",
    "    bigrams.extend(ngrams(tokens, 2))\n",
    "    trigrams.extend(ngrams(tokens, 3))\n",
    "\n",
    "common_unigrams = Counter(unigrams).most_common(500)\n",
    "common_bigrams = Counter(bigrams).most_common(500)\n",
    "common_trigrams = Counter(trigrams).most_common(500)\n",
    "\n",
    "df_unigrams = pd.DataFrame(common_unigrams, columns=[\"word\", \"count\"])\n",
    "df_bigrams = pd.DataFrame(common_bigrams, columns=[\"phrase\", \"count\"])\n",
    "df_trigrams = pd.DataFrame(common_trigrams, columns=[\"phrase\", \"count\"])\n",
    "\n",
    "df_unigrams.to_csv(\"data/prescription_data/common_unigrams.csv\", index=False)\n",
    "df_bigrams.to_csv(\"data/prescription_data/common_bigrams.csv\", index=False)\n",
    "df_trigrams.to_csv(\"data/prescription_data/common_trigrams.csv\", index=False)\n",
    "\n",
    "print(\"Tokenization & phrase extraction complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase lookup dictionary saved!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "unigrams = pd.read_csv(\"data/prescription_data/common_unigrams.csv\")\n",
    "bigrams = pd.read_csv(\"data/prescription_data/common_bigrams.csv\")\n",
    "trigrams = pd.read_csv(\"data/prescription_data/common_trigrams.csv\")\n",
    "\n",
    "phrase_dict = {\n",
    "    \"unigrams\": unigrams.set_index(\"word\").to_dict()[\"count\"],\n",
    "    \"bigrams\": bigrams.set_index(\"phrase\").to_dict()[\"count\"],\n",
    "    \"trigrams\": trigrams.set_index(\"phrase\").to_dict()[\"count\"]\n",
    "}\n",
    "\n",
    "with open(\"data/prescription_data/phrase_lookup.json\", \"w\") as f:\n",
    "    json.dump(phrase_dict, f)\n",
    "\n",
    "print(\"Phrase lookup dictionary saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training data created successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_clean = pd.read_csv(\"data/prescription_data/prescriptions_clean.csv\")\n",
    "\n",
    "df_clean[\"epad_text_clean\"] = df_clean[\"epad_text_clean\"].astype(str).fillna(\"\")\n",
    "\n",
    "train_data = []\n",
    "for text in df_clean[\"epad_text_clean\"]:\n",
    "    words = text.split()\n",
    "    if len(words) < 2:\n",
    "        continue  \n",
    "    for i in range(len(words) - 1):\n",
    "        train_data.append((\" \".join(words[:i+1]), words[i+1]))  # (context, next_word)\n",
    "\n",
    "df_train = pd.DataFrame(train_data, columns=[\"context\", \"next_word\"])\n",
    "\n",
    "df_train.to_csv(\"data/prescription_data/training_data.csv\", index=False)\n",
    "\n",
    "print(\"✅ Training data created successfully!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-GRAM Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "df_train = pd.read_csv(\"data/prescription_data/training_data.csv\")\n",
    "\n",
    "unigrams = []\n",
    "bigrams = []\n",
    "trigrams = []\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    words = row[\"context\"].split()\n",
    "    unigrams.extend(words)\n",
    "    bigrams.extend(ngrams(words, 2))\n",
    "    trigrams.extend(ngrams(words, 3))\n",
    "\n",
    "unigram_freq = FreqDist(unigrams)\n",
    "bigram_freq = FreqDist(bigrams)\n",
    "trigram_freq = FreqDist(trigrams)\n",
    "\n",
    "unigram_prob = {word: unigram_freq[word] / sum(unigram_freq.values()) for word in unigram_freq}\n",
    "bigram_prob = {word: bigram_freq[word] / sum(bigram_freq.values()) for word in bigram_freq}\n",
    "trigram_prob = {word: trigram_freq[word] / sum(trigram_freq.values()) for word in trigram_freq}\n",
    "\n",
    "import pickle\n",
    "with open(\"models/ngram_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"unigram\": unigram_prob, \"bigram\": bigram_prob, \"trigram\": trigram_prob}, f)\n",
    "\n",
    "print(\"N-Gram model trained and saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14a4978fab676977d932eb5fa62cda2c86422c8b9831ddc44bca5fec234ace72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
